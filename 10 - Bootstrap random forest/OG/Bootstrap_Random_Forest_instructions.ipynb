{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bootstrap_Random_Forest_instructions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AjzGopb_YcKR"},"source":["# Application of Bootstrap samples in Random Forest"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zZSCtDI6YcKT","colab":{}},"source":["import numpy as np\n","from sklearn.datasets import load_boston\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import cross_val_score\n","from sklearn.tree import DecisionTreeRegressor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h2Y1Z1DoYcKZ"},"source":[" <li> Load the boston house dataset </li>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wBWRNKCDYcKb","colab":{}},"source":["boston = load_boston()\n","x=boston.data #independent variables\n","y=boston.target #target variable\n","\n","#Concatenating arrays\n","data = np.hstack((boston.data, np.atleast_2d(boston.target).T))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTbK20-mWYHU","colab_type":"code","outputId":"0a9d3800-f3b3-4d43-8558-e8088d3357ba","executionInfo":{"status":"ok","timestamp":1574697197317,"user_tz":-330,"elapsed":2402,"user":{"displayName":"Uday Lunawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApxTeOX5a74pUPlQFOi2bKH68XOrr0Eyu26dSKzQ=s64","userId":"03427549702697233924"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506, 13)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Wa_I46Efwgju","colab_type":"code","outputId":"fe2574cb-c1ef-4980-bf86-2bdd3d963536","executionInfo":{"status":"ok","timestamp":1574697198649,"user_tz":-330,"elapsed":3119,"user":{"displayName":"Uday Lunawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApxTeOX5a74pUPlQFOi2bKH68XOrr0Eyu26dSKzQ=s64","userId":"03427549702697233924"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506, 14)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"itCtnYbjNffa","colab_type":"code","colab":{}},"source":["# a = [[1,2,3,4,50],[5,6,7,8,100],[9,10,11,12,101],[13,14,15,16,102],[17,18,19,20,103]]\n","a = list(data)\n","import random, math\n","generated_samples_input = []\n","generated_samples_target = []\n","sample_models = []\n","selected_columns_30 = []\n","no_of_columns = [ random.randint(3,len(a[0])-1) for _ in range(30) ] #Generating list of no. of columns for each sample\n","for i in range(30):\n","  a60 = random.sample(a, k = math.floor(len(a)*0.6))\n","  a40 = random.sample(a60, k = math.floor(len(a) - len(a60)))\n","  final_sample = a60 + a40\n","  final_sample_array = np.array([np.array(xi) for xi in final_sample]) #Converting list of lists to array\n","  # print(final_sample_array)\n","  final_sample_y = final_sample_array[:, -1]\n","  sample_x = np.delete(final_sample_array, len(final_sample_array[0])-1, axis = 1)\n","  #Generating list of selected columns\n","  z = [i for i in range(0, len(a[0])-1)] #Column index generation\n","  selected_columns = random.sample(z,no_of_columns[i])\n","  selected_columns.sort()\n","  selected_columns_30.append(selected_columns)\n","\n","  #Selecting columns from sample\n","  final_sample_x = sample_x[:, selected_columns]\n","\n","  #Building model\n","  regressor = DecisionTreeRegressor(random_state=0).fit(final_sample_x, final_sample_y)\n","  sample_models.append(regressor)\n","\n","\n","  generated_samples_input.append(final_sample_x)\n","  generated_samples_target.append(final_sample_y)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2vqGSsn2cgx","colab_type":"code","colab":{}},"source":["# for input, target in zip(generated_samples_input, generated_samples_target):\n","#   for i,j in zip(input, target):\n","#     for model in sample_models:\n","#       model.predict(i.reshape(-1, 1))\n","#     break;\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"puTb6N4U7Wud","colab_type":"code","outputId":"56fdfe34-0061-45dd-ba2b-6cbbc1db588b","executionInfo":{"status":"ok","timestamp":1574703356183,"user_tz":-330,"elapsed":1472,"user":{"displayName":"Uday Lunawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApxTeOX5a74pUPlQFOi2bKH68XOrr0Eyu26dSKzQ=s64","userId":"03427549702697233924"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["prediction = []\n","pred = 0\n","for input, model in zip(generated_samples_input, sample_models):\n","  pred += model.predict(input)\n","print(pred/30)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[24.78166667 24.58733333 23.24933333 25.03185185 20.26238095 24.92174129\n"," 23.93533333 23.01007463 20.7248524  21.08340796 21.61578947 26.7345641\n"," 22.71333333 22.85666667 23.64166667 21.48618574 22.13722222 20.43840796\n"," 21.812      23.34866667 21.62611111 24.37388889 21.40507463 21.32666667\n"," 23.42933333 23.27174129 19.046      21.03583333 23.38396352 24.93951907\n"," 23.63571429 22.04416667 24.45507463 23.99714286 22.96174129 23.04174129\n"," 19.19951907 23.5        25.75666667 20.42257143 24.66589744 23.24571429\n"," 21.631      24.72578947 24.73194444 21.81007463 21.34666667 20.74674129\n"," 22.22507463 20.57333333 20.27840796 27.39555556 26.05174129 21.04840796\n"," 24.28666667 22.76222222 23.07166667 20.55507463 19.43888889 21.92255556\n"," 23.31638889 20.65174129 22.016      22.46285714 22.11507463 21.98857143\n"," 23.43396352 22.55844444 24.75644444 20.81285714 23.32377778 23.22\n"," 24.09840796 20.58333333 26.30377778 22.09507463 17.57507463 23.842\n"," 20.29533333 19.64333333 21.0765032  23.40174129 21.58333333 23.635\n"," 26.62507463 23.33633333 21.55936508 24.00194444 23.09388889 24.01764606\n"," 20.14657143 21.59502757 21.0280117  19.61285714 21.77333333 24.08222222\n"," 24.47840796 20.58340796 20.33333333 20.13555556 21.09755556 20.33277778\n"," 25.85185185 22.8025641  21.92333333 20.5737037  22.90222222 19.56367521\n"," 21.87888889 23.89012698 23.49555556 20.94027778 21.90563018 20.98888889\n"," 23.32       24.68507463 19.34222222 21.35729685 22.02507463 19.50666667\n"," 21.58507463 25.18388889 22.85840796 21.68777778 23.27194444 22.18\n"," 23.39764606 20.64111111 25.31194444 25.29396352 22.21578947 25.10571429\n"," 23.00222222 21.46507463 21.01833333 20.46722222 21.03933333 21.1278524\n"," 21.78412281 23.16444444 23.13111111 22.62333333 22.09555556 20.47518519\n"," 21.81590476 22.83333333 21.54333333 23.20840796 21.43333333 23.81185185\n"," 24.77722222 25.69777778 21.10097939 23.61646032 20.70333333 25.07861111\n"," 21.50333333 19.9737037  23.8165032  20.68222222 24.53194444 25.31174129\n"," 23.29507463 22.46457143 26.36840796 21.58840796 23.79583333 23.35416667\n"," 23.26507463 19.71481481 25.07259259 23.45857143 21.77174129 22.15674129\n"," 25.06333333 24.60666667 19.81174129 24.57194444 22.66166667 20.71507463\n"," 19.87745614 22.36111111 22.42       21.82888889 22.32257143 22.46805556\n"," 24.7292381  22.32333333 22.65843712 22.36888889 21.03840796 22.41540796\n"," 21.23666667 22.42888889 21.86396352 21.30185185 20.75777778 27.70666667\n"," 19.94840796 21.83416667 25.44507463 23.34578947 26.71333333 22.65516402\n"," 22.95333333 21.42083333 21.74578947 22.34431272 22.74388889 19.48407463\n"," 24.24       22.54666667 19.60534921 24.49433333 22.686      20.88851852\n"," 21.70277778 21.50174129 24.02888889 20.19840796 21.71515873 21.67840796\n"," 21.73266667 23.37729685 22.51507463 21.35840796 20.502      19.95185185\n"," 20.7947619  21.8668022  20.91333333 23.30333333 22.05007463 20.49507463\n"," 22.04222222 22.5925641  22.40888889 22.114      24.55833333 20.40822222\n"," 23.20222222 24.99903704 21.64555556 24.21685185 21.66380952 23.35833333\n"," 23.76431272 22.70333333 22.77589744 23.26904762 23.31611111 25.34888889\n"," 21.476      22.74590476 22.73666667 24.21111111 24.59433333 23.05340796\n"," 23.94177778 20.92840796 21.90840796 20.95571429 22.33388889 22.39851852\n"," 24.43578947 19.66166667 23.8        22.36083333 23.88166667 20.87333333\n"," 23.36351852 22.01047619 23.756      19.74840796 20.67912281 21.19507463\n"," 19.47578947 20.61333333 22.86174129 23.39       24.10888889 22.54840796\n"," 23.07674129 24.68833333 26.68507463 20.666      21.36777778 24.06518519\n"," 17.85422222 25.15518519 22.63555556 23.47589744 22.68666667 22.97566667\n"," 23.59433333 23.69666667 23.05666667 20.46126984 23.63       26.63507463\n"," 24.63555556 22.68972222 19.50952381 21.6        21.2283609  23.22174129\n"," 20.58507463 23.46888889 22.63866667 19.96888889 25.0125641  23.67555556\n"," 20.642      22.71933333 22.41333333 21.47266667 20.06566667 19.57722222\n"," 25.61738095 22.66979365 23.94174129 21.11840796 20.54222222 20.33666667\n"," 23.51190476 23.3112963  21.97507463 22.15840796 21.84174129 21.88666667\n"," 19.97333333 23.20111111 22.45340796 22.42       24.45222222 24.02\n"," 20.69       20.44266667 25.78923077 24.49972222 19.52912281 24.06587302\n"," 23.91174129 21.08703704 24.66174129 23.43666667 25.73833333 22.46923077\n"," 24.50063018 24.53674129 22.60690058 23.23896352 21.62840796 22.92533333\n"," 21.99851852 23.39055556 21.84666667 22.70311111 23.18007463 19.51433333\n"," 22.30174129 20.095      19.29555556 25.10222222 20.89       25.50888889\n"," 21.45356725 20.69729685 25.23527778 21.64333333 25.35340796 21.68627513\n"," 22.45511111 22.08733333 22.74174129 19.37840796 19.83027778 24.6992381\n"," 25.07388889 23.93590476 23.725      24.03777778 22.36888889 21.58611111\n"," 23.77507463 22.33507463 22.61533333 21.33507463 23.2537037  19.87571429\n"," 24.79833333 20.81169424 24.98431272 21.77097939 22.17174129 20.99245614\n"," 22.82388889 21.27674129 20.172      19.91857143 22.8992381  23.49166667\n"," 19.96285714 21.44555556 22.43666667 24.24555556 24.09174129 21.18840796\n"," 24.47851852 22.93533333 21.04698413 23.78063018 25.22333333 24.04507463\n"," 21.96333333 21.87840796 21.8792381  25.24866667 22.99422222 24.95340796\n"," 21.88185185 23.92666667 20.38666667 21.96685185 24.73933333 21.57666667\n"," 21.62840796 23.58174129 20.56555556 23.86833333 23.79555556 22.57507463\n"," 22.86583333 22.3233609  21.20238095 20.68933333 22.67840796 24.07063018\n"," 20.74063018 23.64555556 22.37833333 22.27840796 23.654      21.58333333\n"," 20.97833333 26.18055556 21.09833333 22.80840796 20.15033333 21.77083333\n"," 20.85833333 22.28666667 21.01851852 25.44066667 22.88257143 22.61166667\n"," 20.68       23.586      21.57174129 24.10089744 21.57007463 21.36266667\n"," 22.50433333 22.79833333 23.54083333 20.42333333 23.66888889 22.1025\n"," 21.56238095 22.35044444 21.30333333 22.38380952 19.88090796 21.19361111\n"," 23.14933333 21.84833333 25.06666667 20.36674129 24.96840796 23.59\n"," 22.39507463 22.81396352 21.23066667 24.89266667 24.74785714 24.24793651\n"," 23.79619048 21.26616667 22.09840796 19.8075     19.67840796 21.57380952\n"," 24.83472222 23.10277778 21.97333333 20.89451907 21.68       21.69266667\n"," 21.06444444 24.41444444 22.95825397 24.27571429 24.65340796 23.142\n"," 26.03840796 22.744     ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZZD35PC3VP0O","colab_type":"code","outputId":"e44fde93-e7f1-4382-dc2f-f511c150869a","executionInfo":{"status":"ok","timestamp":1574703379781,"user_tz":-330,"elapsed":3810,"user":{"displayName":"Uday Lunawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApxTeOX5a74pUPlQFOi2bKH68XOrr0Eyu26dSKzQ=s64","userId":"03427549702697233924"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mse = round(mean_squared_error(y, pred/30), 6)\n","print(mse)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["86.084753\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bLbmvbUPQ9Nk","colab_type":"code","colab":{}},"source":["# a = list(x)\n","# allsamples = []\n","\n","# for i in range(30):\n","#   a60 = random.sample(a,k = math.floor(len(a)*0.6))\n","#   a40 = random.sample(a60,k = math.floor(len(a)*0.4))\n","#   final_sample = a60 + a40\n","#   print(final_sample)\n","#   for sample in final_sample:\n","#     columns = [ random.randint(3,x.shape[1]) for _ in range(30) ]\n","#     print(sample[:, columns])\n","#     break;\n","#   fs = random.sample(final_sample,columns[i])\n","#   allsamples.append(fs)\n","\n","# # print(*allsamples[0], sep = '\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JJ_FwP7xYcKg"},"source":["### Task: 1\n","<font color='red'><b>Step 1 Creating samples: </b></font> Randomly create 30 samples from the whole boston data points.\n","<ol>\n","<li>Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points</li>\n","<li>Ex: For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly consider we have selected [4, 5, 7, 8, 9, 3] now we will replciate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]</li>\n","<li> we create 30 samples like this </li>\n","<li> Note that as a part of the Bagging when you are taking the random samples make sure each of the sample will have                different set of columns</li>\n","<li> Ex: assume we have 10 columns for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample [7, 9, 1, 4, 5, 6, 2] and so on...</li>\n","<li> Make sure each sample will have atleast 3 feautres/columns/attributes</li>\n","</ol>\n","\n","<font color='red'><b>Step 2 Building High Variance Models on each of the sample and finding train MSE value:</b></font> Build a DecisionTreeRegressor on each of the sample.\n","<ol><li>Build a regression trees on each of 30 samples.</li>\n","<li>computed the predicted values of each data point(506 data points) in your corpus.</li>\n","<li> predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n","<li>Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n","</ol>\n","\n","<font color='red'><b>Step 3 Calculating the OOB score :</b></font>\n","<ol>\n","<li>Computed the predicted values of each data point(506 data points) in your corpus.</li>\n","<li>Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n","<li>Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$.</li>\n","</ol>\n","\n","### Task: 2\n","<pre>\n","<font color='red'><b>Computing CI of OOB Score and Train MSE</b></font>\n","<ol>\n","<li> Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n","<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n","<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n","<li> you need to report CI of MSE and CI of OOB Score </li>\n","<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n","</ol>\n","</pre>\n","### Task: 3\n","<pre>\n","<font color='red'><b>Given a single query point predict the price of house.</b></font>\n","\n","<li>Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] Predict the house price for this point as mentioned in the step 2 of Task 1. </li>\n","</pre>"]},{"cell_type":"code","metadata":{"id":"pqgv2qfIQoui","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}