{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a124012",
   "metadata": {},
   "source": [
    "# üéôÔ∏è NotebookLM-Kokoro TTS with GPU Acceleration\n",
    "\n",
    "This notebook implements the NotebookLM-Kokoro TTS system with GPU acceleration and multiprocessing support. It uses Kokoro for text-to-speech generation and Gradio for the user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5964ba",
   "metadata": {},
   "source": [
    "## Setup Environment and Dependencies\n",
    "\n",
    "First, let's install the required packages and configure the GPU environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install kokoro>=0.9.2 gradio soundfile torch PyPDF2 numpy openai\n",
    "\n",
    "# Verify GPU availability \n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import tempfile\n",
    "import gradio as gr\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import ast\n",
    "import shutil\n",
    "import warnings\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import torch\n",
    "from kokoro import KPipeline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configure device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_WORKERS = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5834f686",
   "metadata": {},
   "source": [
    "## Define Helper Functions and System Prompts\n",
    "\n",
    "Set up the core system prompts and helper functions for transcript generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT_WRITER_SYSTEM_PROMPT = \"\"\"\n",
    "You are a world-class storyteller and you have worked as a ghost writer.\n",
    "Welcome the listeners by talking about the Chapter Title.\n",
    "You will be talking to a guest.\n",
    "\n",
    "Do not address the other speaker as Speaker 1 or Speaker 2.\n",
    "\n",
    "Instructions for Speaker 1:\n",
    "Speaker 1: Leads the conversation and teaches the guest, giving incredible anecdotes and analogies when explaining.\n",
    "Speaker 1: Do not address the guest as Speaker 2.\n",
    "\n",
    "Instructions for Speaker 2:\n",
    "Speaker 2: Keeps the conversation on track by asking follow up questions. Gets super excited or confused when asking questions.\n",
    "Speaker 2: Do not address the other speaker as Speaker 1.\n",
    "\"\"\"\n",
    "\n",
    "TRANSCRIPT_REWRITER_SYSTEM_PROMPT = \"\"\"\n",
    "You are an international Oscar-winning screenwriter.\n",
    "Your job is to use the transcript written below to re-write it for an AI Text-To-Speech Pipeline.\n",
    "\n",
    "IMPORTANT FORMAT INSTRUCTIONS:\n",
    "You must return a JSON array of arrays, where each inner array contains exactly two strings:\n",
    "1. The speaker label (either \"Speaker 1\" or \"Speaker 2\")\n",
    "2. The dialogue text\n",
    "\n",
    "YOUR RESPONSE MUST BE VALID JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16604528",
   "metadata": {},
   "source": [
    "## Implement GPU-Accelerated TTS Pipeline\n",
    "\n",
    "Create the Kokoro TTS pipeline with GPU support for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpu_pipeline(lang_code=\"a\", repo_id=\"hexgrad/Kokoro-82M\"):\n",
    "    \"\"\"Initialize Kokoro pipeline with GPU support\"\"\"\n",
    "    pipeline = KPipeline(lang_code=lang_code, repo_id=repo_id)\n",
    "    pipeline.to(DEVICE)\n",
    "    return pipeline\n",
    "\n",
    "def process_segment_gpu(entry_and_voice_map):\n",
    "    \"\"\"Process audio segment with GPU acceleration\"\"\"\n",
    "    entry, voice_map = entry_and_voice_map\n",
    "    speaker, dialogue = entry\n",
    "    chosen_voice = voice_map.get(speaker, \"af_heart\")\n",
    "    \n",
    "    pipeline = create_gpu_pipeline()\n",
    "    generator = pipeline(dialogue, voice=chosen_voice)\n",
    "    \n",
    "    segment_audio = []\n",
    "    with torch.cuda.amp.autocast():  # Enable automatic mixed precision\n",
    "        for _, _, audio in generator:\n",
    "            segment_audio.append(audio)\n",
    "            \n",
    "    if segment_audio:\n",
    "        return np.concatenate(segment_audio, axis=0)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0283b",
   "metadata": {},
   "source": [
    "## Implement Parallel Audio Generation\n",
    "\n",
    "Set up multiprocessing for parallel audio generation with GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea52c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_parallel(script, speaker1_voice, speaker2_voice, output_file):\n",
    "    \"\"\"Generate audio using parallel processing with GPU acceleration\"\"\"\n",
    "    voice_map = {\"Speaker 1\": speaker1_voice, \"Speaker 2\": speaker2_voice}\n",
    "    \n",
    "    try:\n",
    "        transcript_list = ast.literal_eval(script.strip())\n",
    "        entries_with_voice_map = [(entry, voice_map) for entry in transcript_list]\n",
    "        \n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "            results = list(executor.map(process_segment_gpu, entries_with_voice_map))\n",
    "            \n",
    "        all_audio_segments = [r for r in results if r is not None]\n",
    "        if not all_audio_segments:\n",
    "            return None\n",
    "            \n",
    "        # Add pauses between segments\n",
    "        sample_rate = 24000\n",
    "        pause = np.zeros(sample_rate, dtype=np.float32)\n",
    "        final_audio = np.concatenate([seg for pair in zip(all_audio_segments, \n",
    "                                    [pause] * len(all_audio_segments)) for seg in pair][:-1])\n",
    "        \n",
    "        sf.write(output_file, final_audio, sample_rate)\n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in audio generation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78bd99",
   "metadata": {},
   "source": [
    "## Create Gradio Interface\n",
    "\n",
    "Build the Gradio web interface with GPU monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface():\n",
    "    \"\"\"Create Gradio interface with GPU monitoring\"\"\"\n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
    "        gr.Markdown(\"# üéôÔ∏è NotebookLM-Kokoro TTS (GPU-Accelerated)\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                pdf_input = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
    "                speaker1_voice = gr.Dropdown(\n",
    "                    choices=[\"af_heart\", \"af_bella\", \"hf_beta\"],\n",
    "                    value=\"af_heart\",\n",
    "                    label=\"Speaker 1 Voice\"\n",
    "                )\n",
    "                speaker2_voice = gr.Dropdown(\n",
    "                    choices=[\"af_nicole\", \"bf_emma\"],\n",
    "                    value=\"af_nicole\",\n",
    "                    label=\"Speaker 2 Voice\"\n",
    "                )\n",
    "                \n",
    "            with gr.Column():\n",
    "                status = gr.Textbox(label=\"Status\")\n",
    "                audio_output = gr.Audio(label=\"Generated Audio\")\n",
    "                \n",
    "        # Add GPU monitoring\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_info = gr.Markdown(f\"\"\"\n",
    "            üñ•Ô∏è GPU: {torch.cuda.get_device_name(0)}\n",
    "            üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\n",
    "            \"\"\")\n",
    "            \n",
    "    return app\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_gradio_interface()\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24778a49",
   "metadata": {},
   "source": [
    "## Run Demo\n",
    "\n",
    "Test the complete pipeline with an example PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "pdf_path = \"example.pdf\"\n",
    "transcript, _ = generate_podcast_script(pdf_path)\n",
    "audio_file = generate_audio_parallel(transcript, \"af_heart\", \"af_nicole\", \"output.wav\")\n",
    "print(f\"Audio generated: {audio_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
